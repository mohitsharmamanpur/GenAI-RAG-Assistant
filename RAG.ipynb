{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1e53503-a290-43ec-b47a-cd35096b9928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf70518a-9c89-4934-97e5-2e2065b9713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup (pass key directly)\n",
    "genai.configure(api_key=\"AIzaSyBY2qJ0Xq4bkLiuB6v0ZmpO9CUe7H5iCUU\")\n",
    "MODEL = \"gemini-1.5-flash\"\n",
    "EMBED = \"models/text-embedding-004\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4656e5fd-2e93-4afb-9204-bb78d297779b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Read text files\n",
    "docs = []\n",
    "for f in glob.glob(\"data/*.txt\"):\n",
    "    with open(f, \"r\", encoding=\"utf-8\") as file:\n",
    "        docs.append({\"file\": f, \"text\": file.read()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9864f20c-e4b5-4d89-bb4d-f97c1e8b17bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Split into chunks\n",
    "def split_text(text, size=200):\n",
    "    words = text.split()\n",
    "    return [\" \".join(words[i:i+size]) for i in range(0, len(words), size)]\n",
    "\n",
    "chunks = []\n",
    "for d in docs:\n",
    "    for ch in split_text(d[\"text\"]):\n",
    "        chunks.append({\"file\": d[\"file\"], \"text\": ch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23a24a10-8b9f-4777-858a-8fbadc8b6097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create embeddings\n",
    "def embed_text(t):\n",
    "    r = genai.embed_content(model=EMBED, content=t)\n",
    "    return np.array(r[\"embedding\"], dtype=\"float32\")   \n",
    "\n",
    "vecs = np.vstack([embed_text(c[\"text\"]) for c in chunks])\n",
    "vecs = vecs / (np.linalg.norm(vecs, axis=1, keepdims=True) + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ff11e15-50e7-4913-9384-70472cd9fff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Retrieve top matches\n",
    "def search(query, k=3):\n",
    "    qv = embed_text(query)\n",
    "    qv = qv / (np.linalg.norm(qv) + 1e-8)\n",
    "    sims = vecs @ qv\n",
    "    idx = np.argsort(-sims)[:k]\n",
    "    return [chunks[i] for i in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9466342c-7541-405a-aabb-09367df82450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Ask Gemini\n",
    "def ask(query, k=3):\n",
    "    top = search(query, k)\n",
    "    context = \"\\n\\n\".join(c[\"text\"] for c in top)\n",
    "    prompt = f\"\"\"Answer only from this context:\\n{context}\\n\\nQ: {query}\\nA:\"\"\"\n",
    "    model = genai.GenerativeModel(MODEL)\n",
    "    return model.generate_content(prompt).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b20c9fa-c5ee-44ea-a52e-e7975e1d4b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: How do I fix Kubernetes pod restarts?\n",
      "A: Check pod events using: kubectl describe pod <pod-name>.  Common causes are CrashLoopBackOff, OOMKilled, and Readiness/Liveness probe failures. Solutions include increasing resources in the deployment YAML, fixing probe endpoints, or checking node resource limits.\n",
      "\n",
      "\n",
      "Q: How do I keep Docker images small?\n",
      "A: Always start with a lightweight base image (e.g., python:3.9-slim) and use multi-stage builds to reduce the final image size.  Clean up unnecessary packages and caches in the same RUN layer.\n",
      "\n",
      "\n",
      "Q: How can I persist data in Docker?\n",
      "A: Use volumes for persistent data:  `docker volume create data_volume`  Mount with: `docker run -v data_volume:/app/data myimage`\n",
      "\n",
      "\n",
      "Q: How to monitor Kubernetes pods?\n",
      "A: Use `kubectl top pod` to check CPU/Memory usage.  Integrate Prometheus and Grafana for real-time dashboards.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7. Demo\n",
    "if __name__ == \"__main__\":\n",
    "    qs = [\n",
    "        \"How do I fix Kubernetes pod restarts?\",\n",
    "        \"How do I keep Docker images small?\",\n",
    "        \"How can I persist data in Docker?\",\n",
    "        \"How to monitor Kubernetes pods?\"\n",
    "    ]\n",
    "    for q in qs:\n",
    "        print(\"\\nQ:\", q)\n",
    "        print(\"A:\", ask(q))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155a41f4-210c-49b3-8154-2f62dd97cfc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
